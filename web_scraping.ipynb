{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b41bf4-4454-4f31-b146-2435335dfbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7969ec9-7464-4229-a950-28d7bec1a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for the internships with placeholder for page number\n",
    "base_url = 'https://internshala.com/internships/analytics-internship/page-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1415098-689c-4f69-a559-18cd1a38033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_base_url = 'https://internshala.com/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0faa56eb-2145-4435-9195-6ad3b3a8a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store the extracted information\n",
    "name = []         \n",
    "position = []      \n",
    "locations = []     \n",
    "stipend = []       \n",
    "duration = []      \n",
    "link = []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b045d4e-fc4a-4280-a70e-94f45f8ad37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through a range of pages (adjust the range as needed)\n",
    "for page in range(1, 6): \n",
    "   \n",
    "    url = base_url + str(page) + '/'\n",
    "    \n",
    "    # Make a request to the current page\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all the internship meta information from the soup object\n",
    "    company = soup.find_all('div', class_='internship_meta duration_meta')\n",
    "\n",
    "    \n",
    "    for i in company:\n",
    "           \n",
    "            name.append(i.find('p', class_='company-name').text.strip())  # Company name\n",
    "            position.append(i.find('h3', class_=\"job-internship-name\").text.strip())  # Internship position\n",
    "            locations.append(i.find('span').find('a').text.strip())  # Location of the internship\n",
    "            stipend.append(i.find('span', class_='stipend').text.strip())  # Stipend amount\n",
    "            \n",
    "            # Extract the relative link and prepend the base URL\n",
    "            relative_link = i.find('a', class_='job-title-href')['href']  # Relative link to the internship details\n",
    "            link.append(detail_base_url + relative_link)  # Combine base URL with relative link\n",
    "\n",
    "            # Extract duration information\n",
    "            items = i.find_all('div', class_='row-1-item')  # Find all duration items in the current internship\n",
    "            if len(items) > 1:  # Check if there is more than one item\n",
    "                second_item_text = items[1].find('span').text.strip()  # Get the text of the second item\n",
    "                duration.append(second_item_text)  # Append the duration to the duration list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbdad668-d4a9-4781-bfb6-30ae710e4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the scraped data\n",
    "d = {\"Company Name\": name,\"Internship Position\": position,\"Location\": locations,\"Stipend\": stipend,\"Duration\": duration,\n",
    "    \"Link\": link\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47e39b98-aaed-4d7c-94bb-f0d8140f22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary into a Pandas DataFrame\n",
    "data = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "265aa1a8-8d2b-4a2b-b379-986ad0a9f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('analytics-internship_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e355d6-953b-4d47-b716-48f2696385bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5665ed1-8afe-45bd-95d5-d02a49b57f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0dbe39-ac0a-43c1-a89e-807dbfc53903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c1660-1c39-4aaa-af3d-6876c33cc049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
